<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Katherine Tian</title>

    <meta name="author" content="Katherine Tian">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Katherine Tian
                </p>
                <p>I'm a recent graduate from Harvard with a B.A. in CS & Statistics and M.S. in CS. I currently work on making language models better calibrated at <a href="https://irislab.stanford.edu/"> Stanford's Iris Lab</a>, 
                  advised by Professor <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>.
                Previously, at Harvard, I worked on medical vision-language models with Professor <a href="https://pranavrajpurkar.com/">Pranav Rajpurkar</a>, 
                algorithms for personal healthcare with Dr. <a href="https://raazdwivedi.github.io/">Raaz Dwivedi</a> (now Professor at Cornell Tech) 
                and Professor <a href="http://people.seas.harvard.edu/~samurphy/">Susan Murphy</a>. 
                I also interned at Google Brain where I worked on TensorFlow. 

                </p>
                <p>
                  On campus, I was co-head TA for our machine learning class (CS 181) and TF'ed AI Research Experiences (CS 197). 
                  I also served as Career & Academics Director for Women in CS at Harvard and President of MITxHarvard Women in AI.
                </p>
                <p style="text-align:center">
                  <a href="mailto:ktian@college.harvard.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=L8bv390AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/katherine-tian/">Linkedin</a>&nbsp;/&nbsp;
                  <a href="https://twitter.com/kattian_">Twitter</a> 
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:30%">
                <a href="images/kat_tian.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/kat_tian.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research (Selected Work)</h2>
                <p>
                  <!-- I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>. -->
                </p>
              </td>
            </tr>
          <!-- </tbody></table> -->
    
          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
            <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback
                  </span>
                <br>
                <strong>Katherine Tian</strong>*, Eric Mitchell*, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, Christopher D. Manning
                <br>
                <em>In submission, 2023</em>
                <br>
                <a href="https://arxiv.org/abs/2305.14975">[arXiv]</a>
                <!-- <p>Combining DreamBooth (personalized text-to-image) and DreamFusion (text-to-3D) yields high-quality, subject-specific 3D assets with text-driven modifications</p> -->
              </td>
            </tr>

            <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation
                  </span>
                <br>
                Jaehwan Jeong*, <strong>Katherine Tian</strong>*, Andrew Li, Sina Hartung, Fardad Behzadi, Juan Calle, David Osayande, Michael Pohlen, Subathra Adithan, Pranav Rajpurkar
                <br>
                <em><a href="https://2023.midl.io/">
                Medical Imaging with Deep Learning (MIDL)</a>, 2023</em>
                <br>
                <a href="https://arxiv.org/abs/2303.17579">[arXiv]</a>
                <!-- <p>Combining DreamBooth (personalized text-to-image) and DreamFusion (text-to-3D) yields high-quality, subject-specific 3D assets with text-driven modifications</p> -->
              </td>
            </tr>

            <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">Counterfactual inference for sequential experimental design
                  </span>
                <br>
                Raaz Dwivedi*, <strong>Katherine Tian</strong>, Sabina Tomkins, Predrag Klasnja, Susan Murphy, Devavrat Shah
                <br>
                <em>In submission, 2023</em>
                <br>
                <a href="https://arxiv.org/abs/2202.06891">[arXiv]</a>
                <!-- <p>Combining DreamBooth (personalized text-to-image) and DreamFusion (text-to-3D) yields high-quality, subject-specific 3D assets with text-driven modifications</p> -->
              </td>
            </tr>

            <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">Automated clear cell renal carcinoma grade classification with prognostic significance
                  </span>
                <br>
                <strong>Katherine Tian*</strong>, Christopher A Rubadue, Douglas I Lin, Mitko Veta, Michael E Pyle, Humayun Irshad, Yujing J Heng
                <br>
                <em> PloS one Vol. 14 (10), 2019</em>
                <br>
                <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222641">[link]</a>
                <!-- <p>Combining DreamBooth (personalized text-to-image) and DreamFusion (text-to-3D) yields high-quality, subject-specific 3D assets with text-driven modifications</p> -->
              </td>
            </tr>
            
            <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">Technical Note on Transcription Factor Motif Discovery from Importance Scores (TF-MoDISco)
                  </span>
                <br>
                Avanti Shrikumar*, <strong>Katherine Tian</strong>, ≈Ωiga Avsec, Anna Shcherbina, Abhimanyu Banerjee, Mahfuza Sharmin, Surag Nair, Anshul Kundaje                <br>
                <em> Preprint, 2018</em>
                <br>
                <a href="https://arxiv.org/abs/1811.00416">[arXiv]</a>
                <!-- <p>Combining DreamBooth (personalized text-to-image) and DreamFusion (text-to-3D) yields high-quality, subject-specific 3D assets with text-driven modifications</p> -->
              </td>
            </tr>

            <tr>
            <br>     
            </tr>
    </table>
  </body>
</html>
